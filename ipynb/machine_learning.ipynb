{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOhVa5Cs5hBq",
        "outputId": "a6aaad36-493f-4631-9d12-aed869ecc3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n",
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pos  GP   G   A  PTS   PS  EV  PPG  SHG  GW  EVA  PPA  SHA    S   TOI\n",
            "457    1  56   3   7   10  2.3   3    0    0   0    7    0    0   53  1031\n",
            "193    1  78   5  33   38  3.7   3    2    0   0   28    5    0  133  1718\n",
            "598    1  38   0   4    4  0.3   0    0    0   0    4    0    0   33   603\n",
            "532    1  30   1   5    6  2.0   1    0    0   0    5    0    0   25   481\n",
            "592    0  30   5   2    7  0.8   5    0    0   0    2    0    0   44   243\n",
            "..   ...  ..  ..  ..  ...  ...  ..  ...  ...  ..  ...  ...  ...  ...   ...\n",
            "88     1  78  12  39   51  9.2   9    3    0   1   22   17    0  154  1595\n",
            "341    0  48   4   6   10  0.3   4    0    0   1    6    0    0   54   605\n",
            "443    0  25   1   4    5 -0.3   1    0    0   0    4    0    0   19   264\n",
            "231    1  77   3  31   34  5.2   2    1    0   1   20   11    0  140  1628\n",
            "62     0  76  18  36   54  6.1  12    6    0   2   26   10    0  147  1390\n",
            "\n",
            "[7614 rows x 15 columns]\n",
            "Epoch 1/2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-aedd432faccb>:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  X_train_pre = X_train_pre.append(df[cols_train])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179/179 [==============================] - 2s 7ms/step - loss: 8079485698048.0000 - val_loss: 4850251202560.0000\n",
            "Epoch 2/2000\n",
            " 30/179 [====>.........................] - ETA: 0s - loss: 5032020279296.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179/179 [==============================] - 1s 6ms/step - loss: 4781471432704.0000 - val_loss: 4744912830464.0000\n",
            "Epoch 3/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 4665717555200.0000 - val_loss: 4603411169280.0000\n",
            "Epoch 4/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 4508068347904.0000 - val_loss: 4507475378176.0000\n",
            "Epoch 5/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 4344266620928.0000 - val_loss: 4274389254144.0000\n",
            "Epoch 6/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 4166167560192.0000 - val_loss: 4191220137984.0000\n",
            "Epoch 7/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 4097453326336.0000 - val_loss: 4135213072384.0000\n",
            "Epoch 8/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 4045206716416.0000 - val_loss: 4088266227712.0000\n",
            "Epoch 9/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 4021259862016.0000 - val_loss: 4073021243392.0000\n",
            "Epoch 10/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 4006599720960.0000 - val_loss: 4078876753920.0000\n",
            "Epoch 11/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3963666300928.0000 - val_loss: 4055508975616.0000\n",
            "Epoch 12/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3950127349760.0000 - val_loss: 4075376607232.0000\n",
            "Epoch 13/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3938529312768.0000 - val_loss: 3979714756608.0000\n",
            "Epoch 14/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3912722808832.0000 - val_loss: 4045411713024.0000\n",
            "Epoch 15/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3897808388096.0000 - val_loss: 3957834383360.0000\n",
            "Epoch 16/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3897710608384.0000 - val_loss: 3972630577152.0000\n",
            "Epoch 17/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3882406379520.0000 - val_loss: 3965299982336.0000\n",
            "Epoch 18/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3886798602240.0000 - val_loss: 3952743546880.0000\n",
            "Epoch 19/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3869246488576.0000 - val_loss: 4040338178048.0000\n",
            "Epoch 20/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3862391422976.0000 - val_loss: 3946403594240.0000\n",
            "Epoch 21/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3883898241024.0000 - val_loss: 3951923822592.0000\n",
            "Epoch 22/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3861392916480.0000 - val_loss: 3942640779264.0000\n",
            "Epoch 23/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3848471576576.0000 - val_loss: 3936899039232.0000\n",
            "Epoch 24/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3851635654656.0000 - val_loss: 3929178636288.0000\n",
            "Epoch 25/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3858031443968.0000 - val_loss: 3957660057600.0000\n",
            "Epoch 26/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3862587768832.0000 - val_loss: 3920482795520.0000\n",
            "Epoch 27/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3851957305344.0000 - val_loss: 3915950587904.0000\n",
            "Epoch 28/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3878126092288.0000 - val_loss: 3917758070784.0000\n",
            "Epoch 29/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3880831156224.0000 - val_loss: 3913901670400.0000\n",
            "Epoch 30/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3838645370880.0000 - val_loss: 3913189425152.0000\n",
            "Epoch 31/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3864778506240.0000 - val_loss: 3924589543424.0000\n",
            "Epoch 32/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3828289372160.0000 - val_loss: 3916309200896.0000\n",
            "Epoch 33/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3849906290688.0000 - val_loss: 3992410652672.0000\n",
            "Epoch 34/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3851967004672.0000 - val_loss: 3910684377088.0000\n",
            "Epoch 35/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3842161508352.0000 - val_loss: 4022886203392.0000\n",
            "Epoch 36/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3847055998976.0000 - val_loss: 3917738409984.0000\n",
            "Epoch 37/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3826226823168.0000 - val_loss: 3926023995392.0000\n",
            "Epoch 38/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3837449207808.0000 - val_loss: 3936886980608.0000\n",
            "Epoch 39/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3837619601408.0000 - val_loss: 3913548300288.0000\n",
            "Epoch 40/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3826761072640.0000 - val_loss: 3948456443904.0000\n",
            "Epoch 41/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3847591297024.0000 - val_loss: 3982140637184.0000\n",
            "Epoch 42/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3857905876992.0000 - val_loss: 4061313630208.0000\n",
            "Epoch 43/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3827225067520.0000 - val_loss: 3904495419392.0000\n",
            "Epoch 44/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3832676089856.0000 - val_loss: 4020601094144.0000\n",
            "Epoch 45/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3830852354048.0000 - val_loss: 3962562936832.0000\n",
            "Epoch 46/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3826226036736.0000 - val_loss: 3971376742400.0000\n",
            "Epoch 47/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3821311098880.0000 - val_loss: 3933350395904.0000\n",
            "Epoch 48/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3820687196160.0000 - val_loss: 3986429313024.0000\n",
            "Epoch 49/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3823719153664.0000 - val_loss: 3949099220992.0000\n",
            "Epoch 50/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3836731457536.0000 - val_loss: 3933135699968.0000\n",
            "Epoch 51/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3810476949504.0000 - val_loss: 4033506443264.0000\n",
            "Epoch 52/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3820497403904.0000 - val_loss: 3930645069824.0000\n",
            "Epoch 53/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3819034116096.0000 - val_loss: 3918903115776.0000\n",
            "Epoch 54/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3810600943616.0000 - val_loss: 3987048235008.0000\n",
            "Epoch 55/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3829515419648.0000 - val_loss: 3891530301440.0000\n",
            "Epoch 56/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3827544358912.0000 - val_loss: 3883998380032.0000\n",
            "Epoch 57/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3810867019776.0000 - val_loss: 3890047877120.0000\n",
            "Epoch 58/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3805888118784.0000 - val_loss: 3898248265728.0000\n",
            "Epoch 59/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3802498072576.0000 - val_loss: 3883651301376.0000\n",
            "Epoch 60/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3829510438912.0000 - val_loss: 3972161077248.0000\n",
            "Epoch 61/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3822413676544.0000 - val_loss: 3882501537792.0000\n",
            "Epoch 62/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3820039438336.0000 - val_loss: 3982881456128.0000\n",
            "Epoch 63/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3825376952320.0000 - val_loss: 3920608886784.0000\n",
            "Epoch 64/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3820068798464.0000 - val_loss: 3995970043904.0000\n",
            "Epoch 65/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3800651530240.0000 - val_loss: 4099485466624.0000\n",
            "Epoch 66/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3814036340736.0000 - val_loss: 3892298645504.0000\n",
            "Epoch 67/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3806305976320.0000 - val_loss: 3875831808000.0000\n",
            "Epoch 68/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3807353241600.0000 - val_loss: 3901111664640.0000\n",
            "Epoch 69/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3797679341568.0000 - val_loss: 3946227957760.0000\n",
            "Epoch 70/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3788536545280.0000 - val_loss: 3905292337152.0000\n",
            "Epoch 71/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3791989768192.0000 - val_loss: 3887628812288.0000\n",
            "Epoch 72/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3783025491968.0000 - val_loss: 4075670994944.0000\n",
            "Epoch 73/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3803767111680.0000 - val_loss: 3865126895616.0000\n",
            "Epoch 74/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3802026213376.0000 - val_loss: 3869519642624.0000\n",
            "Epoch 75/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3784263073792.0000 - val_loss: 3863979229184.0000\n",
            "Epoch 76/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3790556102656.0000 - val_loss: 3867731558400.0000\n",
            "Epoch 77/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3800789155840.0000 - val_loss: 3873650769920.0000\n",
            "Epoch 78/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3792398974976.0000 - val_loss: 3968203489280.0000\n",
            "Epoch 79/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3783422902272.0000 - val_loss: 3873440006144.0000\n",
            "Epoch 80/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3773613211648.0000 - val_loss: 3924488093696.0000\n",
            "Epoch 81/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3789790642176.0000 - val_loss: 3869040705536.0000\n",
            "Epoch 82/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3781580554240.0000 - val_loss: 3865523781632.0000\n",
            "Epoch 83/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3772615753728.0000 - val_loss: 3856229203968.0000\n",
            "Epoch 84/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3778366930944.0000 - val_loss: 3861654011904.0000\n",
            "Epoch 85/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3773189586944.0000 - val_loss: 3954390859776.0000\n",
            "Epoch 86/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3767638687744.0000 - val_loss: 3920308207616.0000\n",
            "Epoch 87/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3790456487936.0000 - val_loss: 3845010227200.0000\n",
            "Epoch 88/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3783547682816.0000 - val_loss: 3890181046272.0000\n",
            "Epoch 89/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3763884785664.0000 - val_loss: 3878891290624.0000\n",
            "Epoch 90/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3774692982784.0000 - val_loss: 3852016287744.0000\n",
            "Epoch 91/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3765511127040.0000 - val_loss: 3935564988416.0000\n",
            "Epoch 92/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3778874966016.0000 - val_loss: 3844750180352.0000\n",
            "Epoch 93/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3772894150656.0000 - val_loss: 3837227696128.0000\n",
            "Epoch 94/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3759432269824.0000 - val_loss: 3874834612224.0000\n",
            "Epoch 95/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3760219488256.0000 - val_loss: 3852265586688.0000\n",
            "Epoch 96/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3791147237376.0000 - val_loss: 3841902772224.0000\n",
            "Epoch 97/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3751064109056.0000 - val_loss: 3848854306816.0000\n",
            "Epoch 98/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3749038522368.0000 - val_loss: 3832701779968.0000\n",
            "Epoch 99/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3756599541760.0000 - val_loss: 3843272212480.0000\n",
            "Epoch 100/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3771738357760.0000 - val_loss: 3846865158144.0000\n",
            "Epoch 101/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3748484874240.0000 - val_loss: 3833471696896.0000\n",
            "Epoch 102/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3777454931968.0000 - val_loss: 3922140069888.0000\n",
            "Epoch 103/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3751875706880.0000 - val_loss: 3838259232768.0000\n",
            "Epoch 104/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3751033700352.0000 - val_loss: 3833480871936.0000\n",
            "Epoch 105/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3764363460608.0000 - val_loss: 3883126226944.0000\n",
            "Epoch 106/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3741331750912.0000 - val_loss: 3819065835520.0000\n",
            "Epoch 107/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3769601884160.0000 - val_loss: 3858021482496.0000\n",
            "Epoch 108/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3737263276032.0000 - val_loss: 3824207527936.0000\n",
            "Epoch 109/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3735134404608.0000 - val_loss: 3832862736384.0000\n",
            "Epoch 110/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3749857722368.0000 - val_loss: 3866640252928.0000\n",
            "Epoch 111/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3739841724416.0000 - val_loss: 3883046535168.0000\n",
            "Epoch 112/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3723338711040.0000 - val_loss: 3817817505792.0000\n",
            "Epoch 113/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3733471887360.0000 - val_loss: 3928028086272.0000\n",
            "Epoch 114/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3764880670720.0000 - val_loss: 3872020758528.0000\n",
            "Epoch 115/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3739861647360.0000 - val_loss: 3805239836672.0000\n",
            "Epoch 116/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3741394927616.0000 - val_loss: 3799136075776.0000\n",
            "Epoch 117/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3725620150272.0000 - val_loss: 3819960795136.0000\n",
            "Epoch 118/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3727690039296.0000 - val_loss: 3790833188864.0000\n",
            "Epoch 119/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3707069792256.0000 - val_loss: 3827367149568.0000\n",
            "Epoch 120/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3732667629568.0000 - val_loss: 3810288730112.0000\n",
            "Epoch 121/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3706104315904.0000 - val_loss: 3872839696384.0000\n",
            "Epoch 122/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3763030982656.0000 - val_loss: 3838426480640.0000\n",
            "Epoch 123/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3719669219328.0000 - val_loss: 3798062333952.0000\n",
            "Epoch 124/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3710833393664.0000 - val_loss: 3785479159808.0000\n",
            "Epoch 125/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3687479771136.0000 - val_loss: 3808338640896.0000\n",
            "Epoch 126/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3704997806080.0000 - val_loss: 3774714740736.0000\n",
            "Epoch 127/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3711334350848.0000 - val_loss: 3798817308672.0000\n",
            "Epoch 128/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3698448662528.0000 - val_loss: 3923181043712.0000\n",
            "Epoch 129/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3704973688832.0000 - val_loss: 3820342214656.0000\n",
            "Epoch 130/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3701415346176.0000 - val_loss: 3763622903808.0000\n",
            "Epoch 131/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3701334343680.0000 - val_loss: 3870532304896.0000\n",
            "Epoch 132/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3709759127552.0000 - val_loss: 3852411338752.0000\n",
            "Epoch 133/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3730721734656.0000 - val_loss: 3903312363520.0000\n",
            "Epoch 134/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3700478705664.0000 - val_loss: 3774645534720.0000\n",
            "Epoch 135/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3708004073472.0000 - val_loss: 3847165313024.0000\n",
            "Epoch 136/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3699630931968.0000 - val_loss: 3821650575360.0000\n",
            "Epoch 137/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3696765173760.0000 - val_loss: 3785223307264.0000\n",
            "Epoch 138/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3676962553856.0000 - val_loss: 3778315026432.0000\n",
            "Epoch 139/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3703593238528.0000 - val_loss: 3766788292608.0000\n",
            "Epoch 140/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3682555396096.0000 - val_loss: 3905734574080.0000\n",
            "Epoch 141/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3684769726464.0000 - val_loss: 3789949501440.0000\n",
            "Epoch 142/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3685457330176.0000 - val_loss: 3783580450816.0000\n",
            "Epoch 143/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3688717352960.0000 - val_loss: 3789329793024.0000\n",
            "Epoch 144/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3677111713792.0000 - val_loss: 3744261734400.0000\n",
            "Epoch 145/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3675513683968.0000 - val_loss: 3733989621760.0000\n",
            "Epoch 146/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3662838759424.0000 - val_loss: 3732625162240.0000\n",
            "Epoch 147/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3676512190464.0000 - val_loss: 3804254437376.0000\n",
            "Epoch 148/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3671803559936.0000 - val_loss: 3780225007616.0000\n",
            "Epoch 149/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3660578029568.0000 - val_loss: 3733676097536.0000\n",
            "Epoch 150/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3648244154368.0000 - val_loss: 3718120734720.0000\n",
            "Epoch 151/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3663588753408.0000 - val_loss: 3762397118464.0000\n",
            "Epoch 152/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3653770674176.0000 - val_loss: 3718486425600.0000\n",
            "Epoch 153/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3661880885248.0000 - val_loss: 3713346306048.0000\n",
            "Epoch 154/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3662419853312.0000 - val_loss: 3885176979456.0000\n",
            "Epoch 155/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3649224310784.0000 - val_loss: 3789687619584.0000\n",
            "Epoch 156/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3674519371776.0000 - val_loss: 3765289615360.0000\n",
            "Epoch 157/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3673430949888.0000 - val_loss: 3748860788736.0000\n",
            "Epoch 158/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3650063695872.0000 - val_loss: 3702615441408.0000\n",
            "Epoch 159/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3636736032768.0000 - val_loss: 3733656436736.0000\n",
            "Epoch 160/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3659616747520.0000 - val_loss: 3691808817152.0000\n",
            "Epoch 161/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3646989008896.0000 - val_loss: 3724344557568.0000\n",
            "Epoch 162/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3634120884224.0000 - val_loss: 3724209029120.0000\n",
            "Epoch 163/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3657650667520.0000 - val_loss: 3686219382784.0000\n",
            "Epoch 164/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3638506291200.0000 - val_loss: 3789376192512.0000\n",
            "Epoch 165/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3631033090048.0000 - val_loss: 3719003111424.0000\n",
            "Epoch 166/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3619730751488.0000 - val_loss: 3875779903488.0000\n",
            "Epoch 167/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3648193822720.0000 - val_loss: 3704501043200.0000\n",
            "Epoch 168/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3615734104064.0000 - val_loss: 3671318069248.0000\n",
            "Epoch 169/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3626958848000.0000 - val_loss: 3749697028096.0000\n",
            "Epoch 170/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3608952700928.0000 - val_loss: 3674629472256.0000\n",
            "Epoch 171/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3672466259968.0000 - val_loss: 3680069484544.0000\n",
            "Epoch 172/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3636453703680.0000 - val_loss: 3672828018688.0000\n",
            "Epoch 173/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3650102755328.0000 - val_loss: 3777692958720.0000\n",
            "Epoch 174/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3617765720064.0000 - val_loss: 3958393274368.0000\n",
            "Epoch 175/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3631692382208.0000 - val_loss: 3655955644416.0000\n",
            "Epoch 176/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3613256318976.0000 - val_loss: 3657946890240.0000\n",
            "Epoch 177/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3619113926656.0000 - val_loss: 3693522976768.0000\n",
            "Epoch 178/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3593719513088.0000 - val_loss: 3711194628096.0000\n",
            "Epoch 179/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3605006647296.0000 - val_loss: 3658043359232.0000\n",
            "Epoch 180/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3595689787392.0000 - val_loss: 3644150513664.0000\n",
            "Epoch 181/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3623791362048.0000 - val_loss: 3853878820864.0000\n",
            "Epoch 182/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3597975683072.0000 - val_loss: 3662202011648.0000\n",
            "Epoch 183/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3613283844096.0000 - val_loss: 3690879516672.0000\n",
            "Epoch 184/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3592079802368.0000 - val_loss: 3682371108864.0000\n",
            "Epoch 185/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3602168414208.0000 - val_loss: 3715057319936.0000\n",
            "Epoch 186/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3587866361856.0000 - val_loss: 3639687774208.0000\n",
            "Epoch 187/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3599929442304.0000 - val_loss: 3685348016128.0000\n",
            "Epoch 188/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3624530870272.0000 - val_loss: 3747940401152.0000\n",
            "Epoch 189/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3591752908800.0000 - val_loss: 3641375719424.0000\n",
            "Epoch 190/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3593157214208.0000 - val_loss: 4256579452928.0000\n",
            "Epoch 191/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3583183945728.0000 - val_loss: 3622456000512.0000\n",
            "Epoch 192/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3602052284416.0000 - val_loss: 3725550157824.0000\n",
            "Epoch 193/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3656627257344.0000 - val_loss: 3633662656512.0000\n",
            "Epoch 194/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3598380433408.0000 - val_loss: 3660973604864.0000\n",
            "Epoch 195/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3608185405440.0000 - val_loss: 3625985507328.0000\n",
            "Epoch 196/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3601317232640.0000 - val_loss: 3775495143424.0000\n",
            "Epoch 197/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3581894459392.0000 - val_loss: 3753908633600.0000\n",
            "Epoch 198/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3572939358208.0000 - val_loss: 3672702976000.0000\n",
            "Epoch 199/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3557459230720.0000 - val_loss: 3634518294528.0000\n",
            "Epoch 200/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3581893935104.0000 - val_loss: 3685416960000.0000\n",
            "Epoch 201/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3594734272512.0000 - val_loss: 3746143666176.0000\n",
            "Epoch 202/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3621368365056.0000 - val_loss: 3671219503104.0000\n",
            "Epoch 203/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3567802908672.0000 - val_loss: 3631220785152.0000\n",
            "Epoch 204/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3573654224896.0000 - val_loss: 3916071960576.0000\n",
            "Epoch 205/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3579862319104.0000 - val_loss: 3766657220608.0000\n",
            "Epoch 206/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3594801905664.0000 - val_loss: 3614775443456.0000\n",
            "Epoch 207/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3592329363456.0000 - val_loss: 3836577579008.0000\n",
            "Epoch 208/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3572489781248.0000 - val_loss: 4073225715712.0000\n",
            "Epoch 209/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3580826746880.0000 - val_loss: 3686931103744.0000\n",
            "Epoch 210/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3575641800704.0000 - val_loss: 3601103847424.0000\n",
            "Epoch 211/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3563072782336.0000 - val_loss: 3656716124160.0000\n",
            "Epoch 212/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3611179876352.0000 - val_loss: 3608500502528.0000\n",
            "Epoch 213/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3572317290496.0000 - val_loss: 3950459224064.0000\n",
            "Epoch 214/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3590494617600.0000 - val_loss: 3727705243648.0000\n",
            "Epoch 215/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3561444081664.0000 - val_loss: 3634408456192.0000\n",
            "Epoch 216/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3560398389248.0000 - val_loss: 3597538689024.0000\n",
            "Epoch 217/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3573303476224.0000 - val_loss: 3604837826560.0000\n",
            "Epoch 218/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3560990834688.0000 - val_loss: 3598306508800.0000\n",
            "Epoch 219/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3568518823936.0000 - val_loss: 3659323146240.0000\n",
            "Epoch 220/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3582961385472.0000 - val_loss: 3625185705984.0000\n",
            "Epoch 221/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3555570745344.0000 - val_loss: 3660186124288.0000\n",
            "Epoch 222/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3603021692928.0000 - val_loss: 3639823826944.0000\n",
            "Epoch 223/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3566092156928.0000 - val_loss: 3585253834752.0000\n",
            "Epoch 224/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3568494182400.0000 - val_loss: 3707220787200.0000\n",
            "Epoch 225/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3578996195328.0000 - val_loss: 3613644554240.0000\n",
            "Epoch 226/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3547098513408.0000 - val_loss: 3594413146112.0000\n",
            "Epoch 227/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3538619465728.0000 - val_loss: 3658012164096.0000\n",
            "Epoch 228/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3553708998656.0000 - val_loss: 3595110711296.0000\n",
            "Epoch 229/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3568961060864.0000 - val_loss: 3600848781312.0000\n",
            "Epoch 230/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3567532638208.0000 - val_loss: 3620975673344.0000\n",
            "Epoch 231/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3545900253184.0000 - val_loss: 3587853778944.0000\n",
            "Epoch 232/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3562436820992.0000 - val_loss: 3584289144832.0000\n",
            "Epoch 233/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3549616406528.0000 - val_loss: 3575686103040.0000\n",
            "Epoch 234/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3552497893376.0000 - val_loss: 3689308225536.0000\n",
            "Epoch 235/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3552133251072.0000 - val_loss: 3681875394560.0000\n",
            "Epoch 236/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3601682137088.0000 - val_loss: 3706800570368.0000\n",
            "Epoch 237/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3559077707776.0000 - val_loss: 3578156023808.0000\n",
            "Epoch 238/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3563938381824.0000 - val_loss: 3721511043072.0000\n",
            "Epoch 239/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3581806903296.0000 - val_loss: 3606923182080.0000\n",
            "Epoch 240/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3559960084480.0000 - val_loss: 3590631981056.0000\n",
            "Epoch 241/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3591321157632.0000 - val_loss: 3630001029120.0000\n",
            "Epoch 242/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3611040677888.0000 - val_loss: 3714610626560.0000\n",
            "Epoch 243/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3557833834496.0000 - val_loss: 3645478535168.0000\n",
            "Epoch 244/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3544802656256.0000 - val_loss: 3692370329600.0000\n",
            "Epoch 245/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3563330994176.0000 - val_loss: 3585104936960.0000\n",
            "Epoch 246/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3522688450560.0000 - val_loss: 3579534376960.0000\n",
            "Epoch 247/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3554843557888.0000 - val_loss: 3571196100608.0000\n",
            "Epoch 248/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3589308940288.0000 - val_loss: 3736748163072.0000\n",
            "Epoch 249/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3556392042496.0000 - val_loss: 3573518172160.0000\n",
            "Epoch 250/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3547613626368.0000 - val_loss: 3609935740928.0000\n",
            "Epoch 251/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3526576308224.0000 - val_loss: 3626030333952.0000\n",
            "Epoch 252/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3549669621760.0000 - val_loss: 3569061462016.0000\n",
            "Epoch 253/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3565823721472.0000 - val_loss: 3626760929280.0000\n",
            "Epoch 254/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3558270304256.0000 - val_loss: 3909692424192.0000\n",
            "Epoch 255/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3572211646464.0000 - val_loss: 3597197639680.0000\n",
            "Epoch 256/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3562392256512.0000 - val_loss: 3575535370240.0000\n",
            "Epoch 257/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3569677500416.0000 - val_loss: 3589786042368.0000\n",
            "Epoch 258/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3540813611008.0000 - val_loss: 3565154467840.0000\n",
            "Epoch 259/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3532474810368.0000 - val_loss: 3577888112640.0000\n",
            "Epoch 260/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3538179850240.0000 - val_loss: 3563480940544.0000\n",
            "Epoch 261/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3542760292352.0000 - val_loss: 3578721206272.0000\n",
            "Epoch 262/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3517340450816.0000 - val_loss: 3552279265280.0000\n",
            "Epoch 263/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3531796643840.0000 - val_loss: 3644600877056.0000\n",
            "Epoch 264/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3582498701312.0000 - val_loss: 3606119186432.0000\n",
            "Epoch 265/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3543832461312.0000 - val_loss: 3550678351872.0000\n",
            "Epoch 266/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3536303423488.0000 - val_loss: 3559745650688.0000\n",
            "Epoch 267/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3532871172096.0000 - val_loss: 3607354933248.0000\n",
            "Epoch 268/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3525333483520.0000 - val_loss: 3572987592704.0000\n",
            "Epoch 269/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3523900604416.0000 - val_loss: 3596763529216.0000\n",
            "Epoch 270/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3558412124160.0000 - val_loss: 3930307690496.0000\n",
            "Epoch 271/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3561573318656.0000 - val_loss: 3682754101248.0000\n",
            "Epoch 272/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3522491580416.0000 - val_loss: 3745550696448.0000\n",
            "Epoch 273/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3530610180096.0000 - val_loss: 3814742032384.0000\n",
            "Epoch 274/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3523260973056.0000 - val_loss: 3773089972224.0000\n",
            "Epoch 275/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3512667209728.0000 - val_loss: 3577591627776.0000\n",
            "Epoch 276/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3544228036608.0000 - val_loss: 3571859324928.0000\n",
            "Epoch 277/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3506156339200.0000 - val_loss: 3613527375872.0000\n",
            "Epoch 278/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3494828048384.0000 - val_loss: 3579376566272.0000\n",
            "Epoch 279/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3504547823616.0000 - val_loss: 3629712932864.0000\n",
            "Epoch 280/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3566740963328.0000 - val_loss: 3575930945536.0000\n",
            "Epoch 281/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3545462472704.0000 - val_loss: 3676988243968.0000\n",
            "Epoch 282/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3523133571072.0000 - val_loss: 3582748524544.0000\n",
            "Epoch 283/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3516344565760.0000 - val_loss: 3539250446336.0000\n",
            "Epoch 284/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3493110480896.0000 - val_loss: 3545015255040.0000\n",
            "Epoch 285/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3535492612096.0000 - val_loss: 3578800635904.0000\n",
            "Epoch 286/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3527312146432.0000 - val_loss: 3548418670592.0000\n",
            "Epoch 287/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3539138772992.0000 - val_loss: 3596856852480.0000\n",
            "Epoch 288/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3550083547136.0000 - val_loss: 3554915647488.0000\n",
            "Epoch 289/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3532906561536.0000 - val_loss: 3701221097472.0000\n",
            "Epoch 290/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3558789611520.0000 - val_loss: 3657432039424.0000\n",
            "Epoch 291/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3519774982144.0000 - val_loss: 3560640086016.0000\n",
            "Epoch 292/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3502174371840.0000 - val_loss: 3636291436544.0000\n",
            "Epoch 293/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3523022946304.0000 - val_loss: 3600883122176.0000\n",
            "Epoch 294/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3502765768704.0000 - val_loss: 3536366075904.0000\n",
            "Epoch 295/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3541234876416.0000 - val_loss: 3615015043072.0000\n",
            "Epoch 296/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3517676257280.0000 - val_loss: 3578218938368.0000\n",
            "Epoch 297/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3519117524992.0000 - val_loss: 3613069934592.0000\n",
            "Epoch 298/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3506278498304.0000 - val_loss: 3713212350464.0000\n",
            "Epoch 299/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3527715323904.0000 - val_loss: 3584374865920.0000\n",
            "Epoch 300/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3543686447104.0000 - val_loss: 3612897181696.0000\n",
            "Epoch 301/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3509273755648.0000 - val_loss: 3611215790080.0000\n",
            "Epoch 302/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3512940363776.0000 - val_loss: 3777977909248.0000\n",
            "Epoch 303/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3534639333376.0000 - val_loss: 3644183805952.0000\n",
            "Epoch 304/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3512997773312.0000 - val_loss: 3581301489664.0000\n",
            "Epoch 305/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3530000957440.0000 - val_loss: 3547431960576.0000\n",
            "Epoch 306/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3522168094720.0000 - val_loss: 3631830532096.0000\n",
            "Epoch 307/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3513882247168.0000 - val_loss: 3702892789760.0000\n",
            "Epoch 308/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3559090028544.0000 - val_loss: 3548019949568.0000\n",
            "Epoch 309/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3522263252992.0000 - val_loss: 3528964702208.0000\n",
            "Epoch 310/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3571732447232.0000 - val_loss: 3556238688256.0000\n",
            "Epoch 311/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3522538766336.0000 - val_loss: 3545368100864.0000\n",
            "Epoch 312/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3515469004800.0000 - val_loss: 3537306910720.0000\n",
            "Epoch 313/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3530455252992.0000 - val_loss: 3537933697024.0000\n",
            "Epoch 314/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3521375109120.0000 - val_loss: 3531364630528.0000\n",
            "Epoch 315/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3518268964864.0000 - val_loss: 3538405294080.0000\n",
            "Epoch 316/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3497127837696.0000 - val_loss: 3569999413248.0000\n",
            "Epoch 317/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3535125086208.0000 - val_loss: 3565943783424.0000\n",
            "Epoch 318/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3532482674688.0000 - val_loss: 3560662106112.0000\n",
            "Epoch 319/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3504349904896.0000 - val_loss: 3595916279808.0000\n",
            "Epoch 320/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3489170456576.0000 - val_loss: 3567177695232.0000\n",
            "Epoch 321/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3533675429888.0000 - val_loss: 3531633065984.0000\n",
            "Epoch 322/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3516649177088.0000 - val_loss: 3554187673600.0000\n",
            "Epoch 323/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3489724366848.0000 - val_loss: 3637356003328.0000\n",
            "Epoch 324/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3542469836800.0000 - val_loss: 3598117502976.0000\n",
            "Epoch 325/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3506311528448.0000 - val_loss: 3543079845888.0000\n",
            "Epoch 326/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3504427499520.0000 - val_loss: 3608153423872.0000\n",
            "Epoch 327/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3502487896064.0000 - val_loss: 3534747598848.0000\n",
            "Epoch 328/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3500384452608.0000 - val_loss: 3527308738560.0000\n",
            "Epoch 329/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3485295706112.0000 - val_loss: 3541928509440.0000\n",
            "Epoch 330/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3501997424640.0000 - val_loss: 3524447698944.0000\n",
            "Epoch 331/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3511144153088.0000 - val_loss: 3534588215296.0000\n",
            "Epoch 332/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3538281037824.0000 - val_loss: 3562568155136.0000\n",
            "Epoch 333/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3519435767808.0000 - val_loss: 3540722384896.0000\n",
            "Epoch 334/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3492593795072.0000 - val_loss: 3605577859072.0000\n",
            "Epoch 335/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3493905563648.0000 - val_loss: 3645513138176.0000\n",
            "Epoch 336/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3495204487168.0000 - val_loss: 3561490743296.0000\n",
            "Epoch 337/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3485119283200.0000 - val_loss: 3541617868800.0000\n",
            "Epoch 338/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3489062191104.0000 - val_loss: 3518466621440.0000\n",
            "Epoch 339/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3497752788992.0000 - val_loss: 3899096039424.0000\n",
            "Epoch 340/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3542343483392.0000 - val_loss: 3667726172160.0000\n",
            "Epoch 341/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3549387292672.0000 - val_loss: 3591267680256.0000\n",
            "Epoch 342/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3502493663232.0000 - val_loss: 3522620555264.0000\n",
            "Epoch 343/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3496406941696.0000 - val_loss: 3561005776896.0000\n",
            "Epoch 344/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3504958341120.0000 - val_loss: 3509358952448.0000\n",
            "Epoch 345/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3495590363136.0000 - val_loss: 3515073953792.0000\n",
            "Epoch 346/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3502363377664.0000 - val_loss: 3790039154688.0000\n",
            "Epoch 347/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3517937876992.0000 - val_loss: 4023644061696.0000\n",
            "Epoch 348/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3497031892992.0000 - val_loss: 3568537174016.0000\n",
            "Epoch 349/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3525854101504.0000 - val_loss: 3527868940288.0000\n",
            "Epoch 350/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3486920474624.0000 - val_loss: 3564879478784.0000\n",
            "Epoch 351/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3470738325504.0000 - val_loss: 3663998746624.0000\n",
            "Epoch 352/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3481570377728.0000 - val_loss: 3502263500800.0000\n",
            "Epoch 353/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3493371052032.0000 - val_loss: 3510292971520.0000\n",
            "Epoch 354/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3526954057728.0000 - val_loss: 3604214448128.0000\n",
            "Epoch 355/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3495587479552.0000 - val_loss: 3582044930048.0000\n",
            "Epoch 356/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3467008802816.0000 - val_loss: 3541438038016.0000\n",
            "Epoch 357/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3486447566848.0000 - val_loss: 3533671759872.0000\n",
            "Epoch 358/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3471723986944.0000 - val_loss: 3515640184832.0000\n",
            "Epoch 359/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3491758342144.0000 - val_loss: 3722619650048.0000\n",
            "Epoch 360/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3484550168576.0000 - val_loss: 3519074533376.0000\n",
            "Epoch 361/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3485818421248.0000 - val_loss: 3513257033728.0000\n",
            "Epoch 362/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3473531731968.0000 - val_loss: 3551870058496.0000\n",
            "Epoch 363/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3498058711040.0000 - val_loss: 3616024297472.0000\n",
            "Epoch 364/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3500086657024.0000 - val_loss: 3642049953792.0000\n",
            "Epoch 365/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3448472076288.0000 - val_loss: 3547360919552.0000\n",
            "Epoch 366/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3476698955776.0000 - val_loss: 3829087076352.0000\n",
            "Epoch 367/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3468495683584.0000 - val_loss: 3531996921856.0000\n",
            "Epoch 368/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3479064805376.0000 - val_loss: 3712258932736.0000\n",
            "Epoch 369/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3495131873280.0000 - val_loss: 3499781521408.0000\n",
            "Epoch 370/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3467078533120.0000 - val_loss: 3507420397568.0000\n",
            "Epoch 371/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3475435159552.0000 - val_loss: 3503552462848.0000\n",
            "Epoch 372/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3475379322880.0000 - val_loss: 3502797225984.0000\n",
            "Epoch 373/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3525843091456.0000 - val_loss: 3575264837632.0000\n",
            "Epoch 374/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3465170124800.0000 - val_loss: 3641059049472.0000\n",
            "Epoch 375/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3451190247424.0000 - val_loss: 3589050728448.0000\n",
            "Epoch 376/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3460097376256.0000 - val_loss: 3745543356416.0000\n",
            "Epoch 377/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3446258794496.0000 - val_loss: 3521551532032.0000\n",
            "Epoch 378/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3482526416896.0000 - val_loss: 3496128806912.0000\n",
            "Epoch 379/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3469161267200.0000 - val_loss: 3497523937280.0000\n",
            "Epoch 380/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3481450053632.0000 - val_loss: 3536618258432.0000\n",
            "Epoch 381/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3467441864704.0000 - val_loss: 3509669330944.0000\n",
            "Epoch 382/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3474944425984.0000 - val_loss: 3562639196160.0000\n",
            "Epoch 383/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3475590610944.0000 - val_loss: 3542989668352.0000\n",
            "Epoch 384/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3484128903168.0000 - val_loss: 3528937439232.0000\n",
            "Epoch 385/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3473746952192.0000 - val_loss: 3552914964480.0000\n",
            "Epoch 386/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3441469685760.0000 - val_loss: 3612860743680.0000\n",
            "Epoch 387/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3453843931136.0000 - val_loss: 3488987217920.0000\n",
            "Epoch 388/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3470657323008.0000 - val_loss: 3561716973568.0000\n",
            "Epoch 389/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3479578345472.0000 - val_loss: 3491088826368.0000\n",
            "Epoch 390/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3448899108864.0000 - val_loss: 3520643989504.0000\n",
            "Epoch 391/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3451457110016.0000 - val_loss: 3565583859712.0000\n",
            "Epoch 392/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3469094682624.0000 - val_loss: 3566491926528.0000\n",
            "Epoch 393/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3465006546944.0000 - val_loss: 3511712743424.0000\n",
            "Epoch 394/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3461963317248.0000 - val_loss: 3511673946112.0000\n",
            "Epoch 395/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3440886415360.0000 - val_loss: 3610790854656.0000\n",
            "Epoch 396/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3429724061696.0000 - val_loss: 3543712661504.0000\n",
            "Epoch 397/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3482916487168.0000 - val_loss: 3510447374336.0000\n",
            "Epoch 398/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3433573646336.0000 - val_loss: 3545127976960.0000\n",
            "Epoch 399/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3439407923200.0000 - val_loss: 3607016505344.0000\n",
            "Epoch 400/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3450120962048.0000 - val_loss: 3698324930560.0000\n",
            "Epoch 401/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3444442398720.0000 - val_loss: 3487130451968.0000\n",
            "Epoch 402/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3461268635648.0000 - val_loss: 3590135480320.0000\n",
            "Epoch 403/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3496955346944.0000 - val_loss: 3517871816704.0000\n",
            "Epoch 404/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3459073703936.0000 - val_loss: 3497593143296.0000\n",
            "Epoch 405/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3449280266240.0000 - val_loss: 3489086570496.0000\n",
            "Epoch 406/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3484639035392.0000 - val_loss: 3497630367744.0000\n",
            "Epoch 407/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3464570339328.0000 - val_loss: 3537869733888.0000\n",
            "Epoch 408/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3464398110720.0000 - val_loss: 3496878276608.0000\n",
            "Epoch 409/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3465861398528.0000 - val_loss: 3580682305536.0000\n",
            "Epoch 410/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3442378014720.0000 - val_loss: 3503557705728.0000\n",
            "Epoch 411/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3466004267008.0000 - val_loss: 3520745177088.0000\n",
            "Epoch 412/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3460942528512.0000 - val_loss: 3489209253888.0000\n",
            "Epoch 413/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3415317413888.0000 - val_loss: 3503310241792.0000\n",
            "Epoch 414/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3436622643200.0000 - val_loss: 3827746209792.0000\n",
            "Epoch 415/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3421799710720.0000 - val_loss: 3472058744832.0000\n",
            "Epoch 416/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3451161935872.0000 - val_loss: 3580646129664.0000\n",
            "Epoch 417/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3417852870656.0000 - val_loss: 3627510136832.0000\n",
            "Epoch 418/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3472190341120.0000 - val_loss: 3497823043584.0000\n",
            "Epoch 419/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3430263291904.0000 - val_loss: 3535929081856.0000\n",
            "Epoch 420/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3459493920768.0000 - val_loss: 3568149200896.0000\n",
            "Epoch 421/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3432383250432.0000 - val_loss: 3472590372864.0000\n",
            "Epoch 422/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3469414498304.0000 - val_loss: 3536996007936.0000\n",
            "Epoch 423/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3432883945472.0000 - val_loss: 3492060856320.0000\n",
            "Epoch 424/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3411619610624.0000 - val_loss: 3485615259648.0000\n",
            "Epoch 425/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3463898726400.0000 - val_loss: 3475194773504.0000\n",
            "Epoch 426/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3435042701312.0000 - val_loss: 3466190389248.0000\n",
            "Epoch 427/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3419000012800.0000 - val_loss: 3475267649536.0000\n",
            "Epoch 428/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3405639319552.0000 - val_loss: 3492374642688.0000\n",
            "Epoch 429/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3438847459328.0000 - val_loss: 3612138012672.0000\n",
            "Epoch 430/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3411439779840.0000 - val_loss: 3587799252992.0000\n",
            "Epoch 431/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3409715134464.0000 - val_loss: 3495127941120.0000\n",
            "Epoch 432/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3400721760256.0000 - val_loss: 3482498629632.0000\n",
            "Epoch 433/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3396845961216.0000 - val_loss: 3672991596544.0000\n",
            "Epoch 434/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3405279133696.0000 - val_loss: 3519605899264.0000\n",
            "Epoch 435/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3402676568064.0000 - val_loss: 3507086688256.0000\n",
            "Epoch 436/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3388414361600.0000 - val_loss: 3453998858240.0000\n",
            "Epoch 437/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3397509185536.0000 - val_loss: 3498723246080.0000\n",
            "Epoch 438/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3423738527744.0000 - val_loss: 3456528547840.0000\n",
            "Epoch 439/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3409583538176.0000 - val_loss: 3517375840256.0000\n",
            "Epoch 440/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3384885903360.0000 - val_loss: 3745921892352.0000\n",
            "Epoch 441/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3406208696320.0000 - val_loss: 3715992911872.0000\n",
            "Epoch 442/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3393019707392.0000 - val_loss: 3473341415424.0000\n",
            "Epoch 443/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3421032415232.0000 - val_loss: 3471942615040.0000\n",
            "Epoch 444/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3389706731520.0000 - val_loss: 3501103775744.0000\n",
            "Epoch 445/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3395157229568.0000 - val_loss: 3486711808000.0000\n",
            "Epoch 446/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3400749809664.0000 - val_loss: 3506651791360.0000\n",
            "Epoch 447/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3427016376320.0000 - val_loss: 3468689932288.0000\n",
            "Epoch 448/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3388817539072.0000 - val_loss: 3449780699136.0000\n",
            "Epoch 449/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3412832288768.0000 - val_loss: 3470186512384.0000\n",
            "Epoch 450/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3413653061632.0000 - val_loss: 3468867928064.0000\n",
            "Epoch 451/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3443200360448.0000 - val_loss: 3480393613312.0000\n",
            "Epoch 452/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3428289609728.0000 - val_loss: 3636143849472.0000\n",
            "Epoch 453/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3400020525056.0000 - val_loss: 3510542270464.0000\n",
            "Epoch 454/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3406000553984.0000 - val_loss: 3749651939328.0000\n",
            "Epoch 455/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3408888070144.0000 - val_loss: 3492288921600.0000\n",
            "Epoch 456/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3397987336192.0000 - val_loss: 3800762941440.0000\n",
            "Epoch 457/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3387842101248.0000 - val_loss: 3463828996096.0000\n",
            "Epoch 458/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3381843984384.0000 - val_loss: 3452382216192.0000\n",
            "Epoch 459/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3411248414720.0000 - val_loss: 3456724107264.0000\n",
            "Epoch 460/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3366164103168.0000 - val_loss: 3462827868160.0000\n",
            "Epoch 461/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3393863548928.0000 - val_loss: 3462661931008.0000\n",
            "Epoch 462/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3422709874688.0000 - val_loss: 3717446500352.0000\n",
            "Epoch 463/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3408839835648.0000 - val_loss: 3461136777216.0000\n",
            "Epoch 464/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3405885734912.0000 - val_loss: 3442640158720.0000\n",
            "Epoch 465/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3391023742976.0000 - val_loss: 3444494303232.0000\n",
            "Epoch 466/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3409787224064.0000 - val_loss: 3495254818816.0000\n",
            "Epoch 467/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3356432269312.0000 - val_loss: 3465705947136.0000\n",
            "Epoch 468/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3404627443712.0000 - val_loss: 3569227137024.0000\n",
            "Epoch 469/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3428328931328.0000 - val_loss: 3463504723968.0000\n",
            "Epoch 470/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3366091227136.0000 - val_loss: 3934166974464.0000\n",
            "Epoch 471/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3379272351744.0000 - val_loss: 3450303676416.0000\n",
            "Epoch 472/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3374073249792.0000 - val_loss: 3439080243200.0000\n",
            "Epoch 473/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3375770894336.0000 - val_loss: 3427984474112.0000\n",
            "Epoch 474/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3417346408448.0000 - val_loss: 3464993177600.0000\n",
            "Epoch 475/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3371995496448.0000 - val_loss: 3466654121984.0000\n",
            "Epoch 476/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3359985631232.0000 - val_loss: 3607649058816.0000\n",
            "Epoch 477/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3364009017344.0000 - val_loss: 3755849023488.0000\n",
            "Epoch 478/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3403276091392.0000 - val_loss: 3433618472960.0000\n",
            "Epoch 479/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3375119990784.0000 - val_loss: 3480516558848.0000\n",
            "Epoch 480/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3394619834368.0000 - val_loss: 3446125625344.0000\n",
            "Epoch 481/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3389880795136.0000 - val_loss: 3768772460544.0000\n",
            "Epoch 482/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3438829371392.0000 - val_loss: 3437968490496.0000\n",
            "Epoch 483/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3380988346368.0000 - val_loss: 3800508399616.0000\n",
            "Epoch 484/2000\n",
            "179/179 [==============================] - 1s 5ms/step - loss: 3391708725248.0000 - val_loss: 3433819275264.0000\n",
            "Epoch 485/2000\n",
            "179/179 [==============================] - 1s 6ms/step - loss: 3382706438144.0000 - val_loss: 3746970468352.0000\n",
            "Epoch 486/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3394210103296.0000 - val_loss: 3429862998016.0000\n",
            "Epoch 487/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3386334248960.0000 - val_loss: 3497082486784.0000\n",
            "Epoch 488/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3363939811328.0000 - val_loss: 3465402646528.0000\n",
            "Epoch 489/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3379070500864.0000 - val_loss: 3437839515648.0000\n",
            "Epoch 490/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3430201688064.0000 - val_loss: 3512625004544.0000\n",
            "Epoch 491/2000\n",
            "179/179 [==============================] - 1s 3ms/step - loss: 3395020914688.0000 - val_loss: 3552404832256.0000\n",
            "Epoch 492/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3376854597632.0000 - val_loss: 3490428747776.0000\n",
            "Epoch 493/2000\n",
            "179/179 [==============================] - 1s 4ms/step - loss: 3371213520896.0000 - val_loss: 3441027186688.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cols_train = ['Pos', 'GP', 'G', 'A', 'PTS', 'PS', 'EV', 'PPG', 'SHG', 'GW', 'EVA', 'PPA', 'SHA', 'S', 'TOI']\n",
        "X_train_pre = pd.DataFrame()\n",
        "y = []\n",
        "\n",
        "for year in range(2005, 2023):\n",
        "  filename = '/content/' + str(year) + '_merge.csv'\n",
        "\n",
        "  df = pd.read_csv(filename, header=0)\n",
        "\n",
        "  for i in range(0, len(df)):\n",
        "    if df.loc[i, 'Pos'] in ['C', 'RW', 'LW']:\n",
        "      df.loc[i, 'Pos'] = 0\n",
        "    else:\n",
        "      df.loc[i, 'Pos'] = 1\n",
        "    if df.loc[i, 'exchange cap'] < 0 or df.loc[i, 'GP'] < 20:\n",
        "      df.drop(i, inplace=True)\n",
        "\n",
        "  df['Pos'] = np.asarray(df['Pos']).astype(np.int64)\n",
        "\n",
        "  X_train_pre = X_train_pre.append(df[cols_train])\n",
        "  y.append(df['exchange cap'].values)\n",
        "\n",
        "y = np.concatenate(y).tolist()\n",
        "y = np.array(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_pre, y, test_size=0.2)\n",
        "print(X_train)\n",
        "model = Sequential();\n",
        "model.add(Dense(15, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(60, activation='relu'))\n",
        "model.add(Dense(120, activation='relu'))\n",
        "model.add(Dense(190, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath = \"./data/model/Salary.hdf5\"\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor=\"val_loss\", verbose=0, save_best_only=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=32, callbacks=[early_stopping_callback, checkpointer])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/data/model/Salary.hdf5')\n",
        "\n",
        "real_sal = []\n",
        "pred_sal = []\n",
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(25):\n",
        "  real = y_test[i]\n",
        "  prediction = Y_prediction[i]\n",
        "  print(\"실제 연봉: {:.2f}, 예상연봉: {:.2f}\".format(real, prediction))\n",
        "  real_sal.append(real)\n",
        "  pred_sal.append(prediction)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3TrPSjYKeuD",
        "outputId": "8a20db46-adc4-4a31-f36a-decf98ce7426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60/60 [==============================] - 0s 3ms/step\n",
            "실제 연봉: 183051.00, 예상연봉: 3866395.25\n",
            "실제 연봉: 3668592.00, 예상연봉: 2737636.25\n",
            "실제 연봉: 5446742.00, 예상연봉: 4629492.50\n",
            "실제 연봉: 10312499.00, 예상연봉: 5005505.00\n",
            "실제 연봉: 342146.00, 예상연봉: 679914.25\n",
            "실제 연봉: 338052.00, 예상연봉: 473801.62\n",
            "실제 연봉: 4479166.00, 예상연봉: 2980930.50\n",
            "실제 연봉: 180555.00, 예상연봉: 3244295.25\n",
            "실제 연봉: 683282.00, 예상연봉: 398225.09\n",
            "실제 연봉: 3520000.00, 예상연봉: 1248546.12\n",
            "실제 연봉: 3163343.00, 예상연봉: 2041945.12\n",
            "실제 연봉: 395547.00, 예상연봉: 1089763.88\n",
            "실제 연봉: 544674.00, 예상연봉: 654013.62\n",
            "실제 연봉: 302500.00, 예상연봉: 800722.38\n",
            "실제 연봉: 9920245.00, 예상연봉: 5006274.50\n",
            "실제 연봉: 4779354.00, 예상연봉: 4402763.50\n",
            "실제 연봉: 14733865.00, 예상연봉: 5574693.50\n",
            "실제 연봉: 348591.00, 예상연봉: 294595.59\n",
            "실제 연봉: 156750.00, 예상연봉: 342213.03\n",
            "실제 연봉: 3592534.00, 예상연봉: 4767589.50\n",
            "실제 연봉: 404411.00, 예상연봉: 5553312.50\n",
            "실제 연봉: 50613.00, 예상연봉: 354191.66\n",
            "실제 연봉: 2350000.00, 예상연봉: 308396.31\n",
            "실제 연봉: 75000.00, 예상연봉: 2444618.50\n",
            "실제 연봉: 3957457.00, 예상연봉: 4324328.50\n"
          ]
        }
      ]
    }
  ]
}