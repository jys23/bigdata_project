{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZPn7UpP10sB"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://www.capfriendly.com/browse/active/\"\n",
        "#  2006 = 2005 ~ 2006 시즌\n",
        "#  2006 ~ 2023 까지 크롤링\n",
        "for year in range(2006, 2024):\n",
        "  result = []\n",
        "\n",
        "  url = base_url\n",
        "  url +=  \"{}\".format(year)\n",
        "  url += \"?age-calculation-date=october1&display=birthday,country,weightkg,heightcm&hide=expiry-status,salary,skater-stats,goalie-stats\"\n",
        "\n",
        "  for page in range(1, 35):\n",
        "    url += (\"&pg=\" + \"{}\".format(page))\n",
        "    html = urlopen(url)\n",
        "    bs_obj = BeautifulSoup(html, \"html.parser\")\n",
        "    tbody_tag = bs_obj.find(\"tbody\")\n",
        "\n",
        "    for tr in tbody_tag:\n",
        "      row = []\n",
        "      td = tr.find_all(\"td\")\n",
        "      for i in range(11):\n",
        "        row.append(td[i].text)\n",
        "      result.append(row)\n",
        "\n",
        "  df = pd.DataFrame(result)\n",
        "  df.to_csv(\"./{y}sal.csv\".format(y=year-1), header=['PLAYER', 'TEAM', 'AGE', 'DATE OF BIRTH', 'COUNTRY', 'WEIGHT', 'HEIGHT', 'POS', 'HANDED', 'CLAUSE', 'CAP HIT'], index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.capfriendly.com/salary-cap\"\n",
        "\n",
        "html = urlopen(url)\n",
        "bs_obj = BeautifulSoup(html, \"html.parser\")\n",
        "result = []\n",
        "\n",
        "thead_tag = bs_obj.find(\"thead\")\n",
        "th = thead_tag.find_all(\"th\")\n",
        "\n",
        "header = []\n",
        "for i in range(6):\n",
        "  header.append(th[i].text)\n",
        "\n",
        "tbody_tag = bs_obj.find(\"tbody\")\n",
        "for tr in tbody_tag:\n",
        "  row = []\n",
        "  td = tr.find_all(\"td\")\n",
        "  for i in range(6):\n",
        "    row.append(td[i].text)\n",
        "  result.append(row)\n",
        "\n",
        "df = pd.DataFrame(result)\n",
        "df.to_csv('season_salarycap_data.csv', header=header, index=False)"
      ],
      "metadata": {
        "id": "JL3rcGyPHu-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}